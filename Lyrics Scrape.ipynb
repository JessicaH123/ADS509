{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95952cac",
   "metadata": {},
   "source": [
    "# ADS 509 Module 1: APIs and Web Scraping\n",
    "\n",
    "This notebook has two parts. In the first part, you will scrape lyrics from AZLyrics.com. In the second part, you'll run code that verifies the completeness of your data pull. \n",
    "\n",
    "For this assignment you have chosen two musical artists who have at least 20 songs with lyrics on AZLyrics.com. We start with pulling some information and analyzing them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b7ae8",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8969e",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "# for the lyrics scrape section\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c13af3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Lyrics Scrape\n",
    "\n",
    "This section asks you to pull data by scraping www.AZLyrics.com. In the notebooks where you do that work you are asked to store the data in specific ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd7df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = {'dualipa':\"https://www.azlyrics.com/d/dualipa.html\",\n",
    "           'hozier':\"https://www.azlyrics.com/h/hozier.html\"} \n",
    "# we'll use this dictionary to hold both the artist name and the link on AZlyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236c99b",
   "metadata": {},
   "source": [
    "## A Note on Rate Limiting\n",
    "\n",
    "The lyrics site, www.azlyrics.com, does not have an explicit maximum on number of requests in any one time, but in our testing it appears that too many requests in too short a time will cause the site to stop returning lyrics pages. (Entertainingly, the page that gets returned seems to only have the song title to [a Tom Jones song](https://www.azlyrics.com/lyrics/tomjones/itsnotunusual.html).) \n",
    "\n",
    "Whenever you call `requests.get` to retrieve a page, put a `time.sleep(5 + 10*random.random())` on the next line. This will help you not to get blocked. If you _do_ get blocked, which you can identify if the returned pages are not correct, just request a lyrics page through your browser. You'll be asked to perform a CAPTCHA and then your requests should start working again. \n",
    "\n",
    "## Part 1: Finding Links to Songs Lyrics\n",
    "\n",
    "That general artist page has a list of all songs for that artist with links to the individual song pages. \n",
    "\n",
    "Q: Take a look at the `robots.txt` page on www.azlyrics.com. (You can read more about these pages [here](https://developers.google.com/search/docs/advanced/robots/intro).) Is the scraping we are about to do allowed or disallowed by this page? How do you know? \n",
    "\n",
    "A: Based on the robots.txt file, web scraping in generally allowed. Here is the results: \n",
    "\n",
    "* User-agent: *\n",
    "* Disallow: /lyricsdb/\n",
    "* Disallow: /song/\n",
    "* Allow: /\n",
    "\n",
    "* User-agent: 008\n",
    "* Disallow: /\n",
    "\n",
    "The directories /lyricsdb/ and /song/ are not allowed, but all the other directories are ok. And since we're going to be scraping the /lyrics/ directory, we are good to go.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9d31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up a dictionary of lists to hold our links\n",
    "lyrics_pages = defaultdict(list)\n",
    "\n",
    "for artist, artist_page in artists.items() :\n",
    "    # request the page and sleep\n",
    "    r = requests.get(artist_page) # gets webpage content of the url that was provided earlier\n",
    "    time.sleep(5 + 10*random.random())\n",
    "\n",
    "    # now extract the links to lyrics pages from this page\n",
    "    soup = BeautifulSoup(r.text, 'html.parser') #creates a beautiful soup object to access the html content\n",
    "    links = soup.find_all('a', href=True)\n",
    "    lyric_links = [link['href'] for link in links if '/lyrics/' + artist.lower() in link['href']]\n",
    "    base_url = 'https://www.azlyrics.com/'\n",
    "    lyric_links = [base_url + link.lstrip('..') for link in lyric_links]\n",
    "    \n",
    "    # store the links `lyrics_pages` where the key is the artist and the\n",
    "    # value is a list of links. \n",
    "    lyrics_pages[artist] = lyric_links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088ce2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'dualipa': ['https://www.azlyrics.com//lyrics/dualipa/genesis.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/lastdance.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/hotterthanhell.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/betheone.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/idgaf.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/blowyourmindmwah.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/newlove.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/nogoodbyes.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/thinkingboutyou.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/roomfor2.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/lostinyourlight.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/badtogether.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/garden.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/dreams.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/newrules.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/begging.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/homesick.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/goldenslumbersacoustic.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/idrathergoblindlive.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/newrulespianoacousticlive.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/futurenostalgia.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/dontstartnow.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/cool.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/physical.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/levitating.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/prettyplease.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/hallucinate.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/loveagain.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/breakmyheart.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/goodinbed.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/boyswillbeboys.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/levitatingremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/fever.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/weregood.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/ifitaintme.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/thatkindofwoman.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/notmyproblem.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/levitatingtheblessedmadonnaremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/hallucinatepaulwoolfordremixextended.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/dontstartnowkaytranadaremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/physicalmarkronsonremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/loveisreligiontheblessedmadonnaremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/breakmyheartmoodymanremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/thatkindofwomanjacqueslucontremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/prettypleasemastersatworkremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/boyswillbeboyszachwitnessremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/goodinbedgenhoshinoremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/futurenostalgiajoegoddardremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/loveagainhorsemeatdiscoremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/cooljaydagremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/dontstartnowyaejiremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/hallucinatemrfingersdeepstrippedmix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/prettypleasemidlandrefix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/goodinbedzachwitnessremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/endofanera.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/houdini.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/trainingseason.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/thesewalls.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/whatchadoing.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/frenchexit.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/illusion.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/fallingforever.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/anythingforlove.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/maria.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/happyforyou.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/258.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/actofgod.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/afterlight.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/allornothing.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/alltomyself.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/badidea.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/ballandchain.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/bangbang.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/berlinsummer.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/betweenabulletandheartbreak.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/breakmyheartcosmicgirldimitrifromparisedit.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/cantheyhearus.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/cherry.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/cocoabutterkisses.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/dancethenight.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/electricity.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/forjulian.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/goodthings.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/guilty.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/high.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/houdiniextendededit.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/idgafdiabloremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/idgafremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/jealousy.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/kissandmakeup.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/kissandmakeupsoloversion.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/losemyself.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/loveisreligion.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/newrulesforcoviddating.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/newyorkmendmybrokenheart.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/physicalremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/running.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/savesomeone.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/secrets.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/swansong.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/talkaboutit.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/tellingitlikeitis.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/thinkingboutyoudeccoremix.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/topdollar.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/try.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/voodoo.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/wantto.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/wanttodemo.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/whatilike.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/wickedandwild.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/wrongnumber.html',\n",
       "              'https://www.azlyrics.com//lyrics/dualipa/yours.html'],\n",
       "             'hozier': ['https://www.azlyrics.com//lyrics/hozier/takemetochurch.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/angelofsmalldeaththecodeinescene.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/jackieandwilson.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/someonenew.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/tobealone.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/fromeden.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/inaweek.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/sedated.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/worksong.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/likerealpeopledo.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/itwillcomeback.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/foreignersgod.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/cherrywine.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/inthewoodssomewhere.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/run.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/arsonistslullabye.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/mylovewillneverdie.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/ninacriedpower.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/nfwmb.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/momentssilencecommontongue.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/shrike.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/ninacriedpower.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/almostsweetmusic.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/movement.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/noplan.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/nobody.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/tonoisemakingsing.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/asitwas.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/shrike.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/talk.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/be.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/dinnerdiatribes.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/wouldthati.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/sunlight.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/wastelandbaby.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/deselbypart1.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/deselbypart2.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/firsttime.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/francesca.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/icarrionicarian.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/eatyouryoung.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/damagegetsdone.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/whoweare.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/allthingsend.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/tosomeonefromawarmclimateuiscefhuaraithe.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/butcheredtongue.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/anythingbut.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/abstractpsychopomp.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/unknownnth.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/firstlight.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/toosweet.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/wildflowerandbarley.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/empirenow.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/farewell.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/betterlove.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/blood.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/blooduponthesnow.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/doiwannaknow.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/icouldbeyours.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/jackbootjumplive.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/laymedown.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/problem.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/saymyname.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/sorrynotsorry.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/swanuponleda.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/sweetthing.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/thepartingglass.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/thewages.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/throughmetheflood.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/wholelottalove.html',\n",
       "              'https://www.azlyrics.com//lyrics/hozier/whywouldyoubeloved.html']})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af59cb",
   "metadata": {},
   "source": [
    "Here is the link to the html code for the artist Hozier - view-source:https://www.azlyrics.com/h/hozier.html\n",
    "\n",
    "* The \"links\" variable stores looks at the html code for the webpage where it has <'a'> tags, indicating hyperlinks. \n",
    "* The \"lyric_links\" variable further filters the \"links\" variable to only show the hyperlinks that are lyrics of the artist.\n",
    "* The most recent \"lyrics_links\" puts the base_url and the previous link together to create a working url."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c285ec1",
   "metadata": {},
   "source": [
    "Let's make sure we have enough lyrics pages to scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4cda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist, lp in lyrics_pages.items() :\n",
    "    assert(len(set(lp)) > 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edca10d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dualipa we have 112.\n",
      "The full pull will take for this artist will take 0.31 hours.\n",
      "For hozier we have 71.\n",
      "The full pull will take for this artist will take 0.2 hours.\n"
     ]
    }
   ],
   "source": [
    "# Let's see how long it's going to take to pull these lyrics \n",
    "# if we're waiting `5 + 10*random.random()` seconds \n",
    "for artist, links in lyrics_pages.items() : \n",
    "    print(f\"For {artist} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this artist will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91217ba",
   "metadata": {},
   "source": [
    "There's actually 124 songs for dua lip, but the code wasn't able to pull some of them since the format was different for some songs. Instead of \n",
    "* <'div' class=\"listalbum-item\"><'a' href=\"/lyrics/dualipa/prettyplease.html\" target=\"_blank\">Pretty Please</'a'></'div'>  \n",
    "it was\n",
    "\n",
    "* <'div' class=\"listalbum-item\"><'a' href=\"https://www.azlyrics.com/lyrics/mileycyrus/prisoner.html\" target=\"_blank\">Prisoner</'a'><'div' class=\"comment\">(The Moonlight Edition Bonus Track)</'div'></'div'>\n",
    "\n",
    "There were 2 formats that were used when creating this html page. For this assignment however, i think 112 songs is suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011be6c6",
   "metadata": {},
   "source": [
    "## Part 2: Pulling Lyrics\n",
    "\n",
    "Now that we have the links to our lyrics pages, let's go scrape them! Here are the steps for this part. \n",
    "\n",
    "1. Create an empty folder in our repo called \"lyrics\". \n",
    "1. Iterate over the artists in `lyrics_pages`. \n",
    "1. Create a subfolder in lyrics with the artist's name. For instance, if the artist was Cher you'd have `lyrics/cher/` in your repo.\n",
    "1. Iterate over the pages. \n",
    "1. Request the page and extract the lyrics from the returned HTML file using BeautifulSoup.\n",
    "1. Use the function below, `generate_filename_from_url`, to create a filename based on the lyrics page, then write the lyrics to a text file with that name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67693711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename_from_link(link) :\n",
    "    \n",
    "    if not link :\n",
    "        return None\n",
    "\n",
    "    # drop the http or https and the html\n",
    "    name = link\n",
    "    name = name.replace(\"https://\",\"\").replace(\"http://\",\"\")\n",
    "    name = name.replace(\".html\",\"\")\n",
    "\n",
    "    name = name.replace(\"/lyrics/\",\"\")\n",
    "\n",
    "    \n",
    "    # Replace useless chareacters with UNDERSCORE\n",
    "    name = name.replace(\".\",\"_\").replace(\"/\",\"_\")\n",
    "    \n",
    "    # tack on .txt\n",
    "    name = name + \".txt\"\n",
    "    \n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0286db45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\jessh\\Documents\\ADS509\n"
     ]
    }
   ],
   "source": [
    "# Make the lyrics folder here. If you'd like to practice your programming, add functionality \n",
    "# that checks to see if the folder exists. If it does, then use shutil.rmtree to remove it and create a new one.\n",
    "# checking if the directory is correct\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7a12a",
   "metadata": {},
   "source": [
    "### 1. Build a subfolder for the artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "418abf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a new folder called lyrics\n",
    "os.mkdir(\"lyrics\")\n",
    "\n",
    "#if os.path.isdir(\"lyrics\") : \n",
    "#    shutil.rmtree(\"lyrics/\")\n",
    "\n",
    "#os.mkdir(\"lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6288fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\jessh\\Documents\\ADS509\\lyrics\n"
     ]
    }
   ],
   "source": [
    "# changing directory\n",
    "lyrics_directory = \"C:/Users/jessh/Documents/ADS509/lyrics\"\n",
    "os.chdir(lyrics_directory)\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1133657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to pull at least 20 songs per artist. It may be fun to pull all the songs for the artist\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# iterate over the artist and their lyrics pages\n",
    "for artist in lyrics_pages :\n",
    "\n",
    "    # Use this space to carry out the following steps: \n",
    "    # creating a folder for the artist the loop is currently on\n",
    "    artist_dir = os.mkdir(artist)\n",
    "    \n",
    "    # changing directory to the artist folder\n",
    "    new_directory = \"C:/Users/jessh/Documents/ADS509/lyrics/\" + artist\n",
    "    os.chdir(new_directory)\n",
    "    \n",
    "    # Limit the number of links to 20\n",
    "    limited_pages = lyrics_pages[artist][:20]\n",
    "    \n",
    "    for page in limited_pages:\n",
    "        \n",
    "        # getting the filename from link\n",
    "        name = generate_filename_from_link(page)\n",
    "        \n",
    "        #3. Request the lyrics page. \n",
    "        # sending a GET request to the link\n",
    "        response = requests.get(page)\n",
    "        time.sleep(5 + 10*random.random())\n",
    "        \n",
    "        # checking if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            \n",
    "            # 4. Extract the title and lyrics from the page.\n",
    "            # parsing the HTML content\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # finding the div containing the lyrics\n",
    "            lyrics_div = soup.find('div', class_='col-xs-12 col-lg-8 text-center')\n",
    "            \n",
    "            #5. Write out the title, two returns ('\\n'), and the lyrics.\n",
    "            # getting the lyrics\n",
    "            lyrics = lyrics_div.text.strip()\n",
    "                \n",
    "            # finding the index of \"Submit Corrections\"\n",
    "            submit_index = lyrics.find(\"Submit Corrections\")\n",
    "\n",
    "            # only getting the lyrics portion, the \"Submit Corrections\" portion was after the lyrics portion\n",
    "            lyrics = lyrics[:submit_index]\n",
    "\n",
    "            # Save the lyrics to a file\n",
    "            with open(f\"{name}\", \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(lyrics)\n",
    "                        \n",
    "    os.chdir(lyrics_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c394f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total run time was 0.12 hours.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total run time was {round((time.time() - start)/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c05e7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_directory = \"C:/Users/jessh/Documents/ADS509\"\n",
    "os.chdir(orig_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cf14b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "This assignment asks you to pull data by scraping www.AZLyrics.com.  After you have finished the above sections , run all the cells in this notebook. Print this to PDF and submit it, per the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "217c2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple word extractor from Peter Norvig: https://norvig.com/spell-correct.html\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37778a1c",
   "metadata": {},
   "source": [
    "## Checking Lyrics \n",
    "\n",
    "The output from your lyrics scrape should be stored in files located in this path from the directory:\n",
    "`/lyrics/[Artist Name]/[filename from URL]`. This code summarizes the information at a high level to help the instructor evaluate your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ba797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bccac29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dualipa we have 20 files.\n",
      "For dualipa we have roughly 7494 words, 718 are unique.\n",
      "For hozier we have 20 files.\n",
      "For hozier we have roughly 5710 words, 1021 are unique.\n"
     ]
    }
   ],
   "source": [
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
    "\n",
    "for artist in artist_folders : \n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "\n",
    "    print(f\"For {artist} we have {len(artist_files)} files.\")\n",
    "\n",
    "    artist_words = []\n",
    "\n",
    "    for f_name in artist_files : \n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile : \n",
    "            artist_words.extend(words(infile.read()))\n",
    "\n",
    "            \n",
    "    print(f\"For {artist} we have roughly {len(artist_words)} words, {len(set(artist_words))} are unique.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e5bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
